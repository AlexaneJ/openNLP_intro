This is one example of tokenizer.
I<SPLIT>,<SPLIT>you<SPLIT>,<SPLIT>everyone<SPLIT>can<SPLIT>tokenize<SPLIT>.<SPLIT>
Triangle<SPLIT>,<SPLIT>rectangle<SPLIT>,<SPLIT>circle<SPLIT>,<SPLIT>line<SPLIT>are<SPLIT>shapes<SPLIT>.<SPLIT>